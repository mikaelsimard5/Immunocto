[BASEMODEL]
Backbone           = "resnet50"
Batch_Size         = 256
Loss_Function      = "CrossEntropyLoss"
Precision          = "16-mixed"
Target_Pixel_Size  = 0.5 # target pixel size in microns. 
Target_Patch_Size  = [42] # Num pixels for training patches. If list -> can train on multiple levels.

[ADVANCEDMODEL]
Inference          = false
Max_Epochs         = 50
Pretrained         = false
Random_Seed        = 42

[AUGMENTATION]
Colour_Sigma       = 0.012
Colour_Mode        = 'uniform'

[CHECKPOINT]
Mode               = "min"
Monitor            = "val_loss_epoch"
logger_folder      = "lightning_logs/trainer_lizard_SAM_ConvNet/" # change according to specifics
model_name         = "temp"

[DATA]
data_file          = "/home/dgs1/data/Lizard/Test_formatted_data/Lizard_dataset.csv"
valid_labels       = ["epithelial", "connective", "lymphocyte", "plasma", "eosinophil", "neutrophil"]
Train_Size         = 0.72 
Val_Size           = 0.18 # so that we do 80/20 split with my scheme
Test_Size          = 0.10
Fold               = [1]    # Fold goes from 1 to 5, we train 5 models for example


[OPTIMIZER]
Algorithm          = 'Adam'
eps                = 1e-7
lr                 = 1e-4

[REGULARIZATION]
Label_Smoothing    = 0.03
Stoch_Depth        = 0
Weight_Decay       = 3e-4

[SCHEDULER]
lin_gamma          = 0.8
lin_step_size      = 6
type               = 'CosineAnnealingLR' #'stepLR'